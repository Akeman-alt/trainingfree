import torch
import torch.nn as nn

# æ ‡å‡†æ°¨åŸºé…¸é¡ºåº
RESTYPES = 'ACDEFGHIKLMNPQRSTVWY'

class BaseReward(nn.Module):
    def __init__(self, device):
        super().__init__()
        self.device = device
    
    def forward(self, seq_samples):
        raise NotImplementedError

class TargetReward(BaseReward):
    """
    ç®€å•ç²—æš´ï¼šè®¡ç®—æŒ‡å®šçš„ä¸€ç»„æ°¨åŸºé…¸çš„æ€»å æ¯”ã€‚
    ä¾‹å¦‚ target_chars=['A', 'V']ï¼Œåˆ™ Reward = (Açš„æ•°é‡ + Vçš„æ•°é‡) / æ€»é•¿åº¦
    """
    def __init__(self, device, target_chars=['A'], vocab_order=RESTYPES):
        super().__init__(device)
        
        self.target_chars = target_chars
        self.vocab_size = len(vocab_order) + 1
        
        # åˆ›å»ºä¸€ä¸ªæŸ¥åˆ†è¡¨ï¼šæ˜¯ç›®æ ‡æ°¨åŸºé…¸çš„ä½ç½®å¡« 1.0ï¼Œå¦åˆ™å¡« 0.0
        self.reward_mask = torch.zeros(self.vocab_size, device=device)
        
        print(f"ğŸ¯ åˆå§‹åŒ–å¥–åŠ±å‡½æ•°: å¢åŠ  {target_chars} çš„å«é‡")
        
        found_any = False
        for char in target_chars:
            if char in vocab_order:
                idx = vocab_order.index(char)
                self.reward_mask[idx] = 1.0
                found_any = True
            else:
                print(f"âš ï¸ è­¦å‘Š: æ°¨åŸºé…¸ {char} ä¸åœ¨è¯è¡¨ä¸­ï¼")
        
        if not found_any:
            raise ValueError("ç›®æ ‡æ°¨åŸºé…¸åˆ—è¡¨æ— æ•ˆï¼Œæ— æ³•è®¡ç®—å¥–åŠ±ï¼")

    def forward(self, seq_samples):
        # seq_samples: [N, B, L] (æ•´æ•°ç´¢å¼•)
        
        # 1. æŸ¥è¡¨ï¼šç›´æ¥æŠŠ token ID å˜æˆ 0 æˆ– 1
        # [N, B, L] -> [N, B, L] (float)
        hits = self.reward_mask[seq_samples.long()]
        
        # 2. ç®—å¹³å‡å€¼ (å æ¯”)
        # [N, B]
        return hits.mean(dim=-1)