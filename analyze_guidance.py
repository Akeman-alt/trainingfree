import os
import glob
import pandas as pd
import numpy as np
import matplotlib

# è®¾ç½® matplotlib åç«¯ï¼Œé˜²æ­¢åœ¨æ²¡æœ‰æ˜¾ç¤ºå™¨çš„æœåŠ¡å™¨ä¸ŠæŠ¥é”™
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import logging
import sys


# ================= é…ç½®åŒºåŸŸ =================
# ğŸ¯ å¥–åŠ±å®šä¹‰ï¼šå¿…é¡»ä¸ flow_module.py å®Œå…¨ä¸€è‡´
TARGET_CHAR = 'A' 

def setup_logger(save_dir):
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿï¼šåŒæ—¶è¾“å‡ºåˆ°å±å¹•å’Œæ–‡ä»¶
    ä¿å­˜è·¯å¾„ï¼šrun_dir/analysis_result.log
    """
    log_file = os.path.join(save_dir, 'analysis_result.log')
    
    # è·å– root logger
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # æ¸…ç©ºå·²æœ‰çš„ handlersï¼Œé˜²æ­¢é‡å¤æ‰“å°
    if logger.hasHandlers():
        logger.handlers.clear()

    # 1. æ–‡ä»¶è¾“å‡º Handler
    file_handler = logging.FileHandler(log_file, mode='w')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
    logger.addHandler(file_handler)

    # 2. å±å¹•è¾“å‡º Handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(logging.Formatter('%(message)s')) # å±å¹•ä¸Šçœ‹ç€æ¸…çˆ½ç‚¹ï¼Œä¸ç”¨æ—¶é—´æˆ³
    logger.addHandler(console_handler)
    
    logger.info(f"ğŸ“ æ—¥å¿—å°†è‡ªåŠ¨ä¿å­˜è‡³: {log_file}")
    return logger

def calculate_reward(sequence):
    """è®¡ç®—åºåˆ—ä¸­ç›®æ ‡æ°¨åŸºé…¸çš„å æ¯”"""
    if not isinstance(sequence, str) or len(sequence) == 0:
        return 0.0
    return sequence.count(TARGET_CHAR) / len(sequence)

def analyze_experiment(run_dir):
    # åˆå§‹åŒ–æ—¥å¿—
    logger = setup_logger(run_dir)
    
    logger.info(f"ğŸš€ æ­£åœ¨åˆ†æç›®å½•: {run_dir}")
    logger.info(f"ğŸ¯ ç›®æ ‡æ°¨åŸºé…¸: '{TARGET_CHAR}'")
    
    # 1. å¯»æ‰¾æ‰€æœ‰çš„ sc_results.csv
    # ä½ çš„ç›®å½•ç»“æ„ä¼¼ä¹æ˜¯ run_dir/length_*/sample_*/sc_results.csv
    search_pattern = os.path.join(run_dir, "length_*", "sample_*", "sc_results.csv")
    csv_files = glob.glob(search_pattern)
    
    if not csv_files:
        logger.error(f"âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {search_pattern}")
        return

    data_list = []
    logger.info(f"â³ æ­£åœ¨è¯»å– {len(csv_files)} ä¸ªæ ·æœ¬...")

    for f in csv_files:
        try:
            df = pd.read_csv(f)
            # ä¼˜å…ˆå– RMSD æœ€ä½çš„é‚£æ¡ï¼ˆä»£è¡¨è¯¥æ¬¡é‡‡æ ·çš„æœ€ä½³ç»“æœï¼‰
            if 'bb_rmsd' in df.columns:
                best_row = df.sort_values(by='bb_rmsd', ascending=True).iloc[0]
            else:
                best_row = df.iloc[0]

            # è·å–åºåˆ— (å…¼å®¹ä¸åŒåˆ—å)
            sequence = best_row.get('sequence', '')
            if not isinstance(sequence, str):
                # å¦‚æœ csv é‡Œæ²¡åºåˆ—ï¼Œå°è¯•å»è¯» fasta
                sample_dir = os.path.dirname(f)
                codesign_path = os.path.join(sample_dir, "self_consistency", "codesign_seqs", "codesign.fa")
                if os.path.exists(codesign_path):
                    with open(codesign_path, 'r') as fa:
                        lines = fa.readlines()
                        if len(lines) >= 2: sequence = lines[1].strip()

            # è®¡ç®—å¥–åŠ±
            reward = calculate_reward(sequence)
            rmsd = best_row.get('bb_rmsd', np.nan)

            data_list.append({
                'reward': reward,
                'rmsd': rmsd,
                'sequence': sequence,
                'length': len(sequence)
            })
            
        except Exception as e:
            logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å‡ºé”™ {f}: {e}")
            continue

    df_all = pd.DataFrame(data_list)
    
    if len(df_all) == 0:
        logger.error("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return

    # 2. ç»Ÿè®¡ç»“æœ
    avg_reward = df_all['reward'].mean()
    avg_rmsd = df_all['rmsd'].mean()
    max_reward = df_all['reward'].max()

    logger.info("\n" + "="*50)
    logger.info("       ğŸ§ª å®éªŒç»“æœæœ€ç»ˆæ ¸å¯¹       ")
    logger.info("="*50)
    logger.info(f"ã€Rewardã€‘ (A çš„å æ¯”)")
    logger.info(f"  å¹³å‡å€¼ : {avg_reward:.2%} (Baselineé€šå¸¸ < 10%)")
    logger.info(f"  æœ€å¤§å€¼ : {max_reward:.2%}")
    logger.info("-" * 50)
    logger.info(f"ã€RMSDã€‘ (ç»“æ„ç¨³å®šæ€§)")
    logger.info(f"  å¹³å‡å€¼ : {avg_rmsd:.4f} Ã…")
    logger.info("="*50)

    # 3. ğŸ‘ï¸ è§†è§‰æ ¸å¯¹ï¼šæ‰“å° Top 3 åºåˆ—
    logger.info("\nğŸ†ã€Top 3 é«˜åˆ†åºåˆ—å±•ç¤ºã€‘")
    top_seqs = df_all.sort_values(by='reward', ascending=False).head(3)
    for i, row in top_seqs.iterrows():
        seq = row['sequence']
        display_seq = seq[:50] + "..." if len(seq) > 50 else seq
        logger.info(f"Runs: {row['reward']:.2%} | Seq: {display_seq}")

    # 4. ç»˜å›¾
    # å›¾ç‰‡ä¿å­˜åˆ° run_dir ä¸‹ï¼Œè€Œä¸æ˜¯å½“å‰ä»£ç ç›®å½•ï¼Œé˜²æ­¢è¦†ç›–
    plot_path = os.path.join(run_dir, "check_reward_dist.png")
    
    plt.figure(figsize=(10, 4))
    sns.histplot(df_all['reward'], bins=20, kde=True, color='green')
    plt.title(f'Distribution of Alanine (A) Content\nMean: {avg_reward:.2%}')
    plt.xlabel('Fraction of A')
    plt.axvline(0.08, color='red', linestyle='--', label='Natural Baseline')
    plt.legend()
    plt.savefig(plot_path)
    plt.close() # å…³é—­ç”»å¸ƒï¼Œé‡Šæ”¾å†…å­˜
    
    logger.info(f"\nğŸ“Š åˆ†å¸ƒå›¾å·²ä¿å­˜: {plot_path}")

if __name__ == "__main__":
    # ä½¿ç”¨ argparse è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="Analyze MultiFlow guidance experiment results.")
    parser.add_argument('--run_dir', type=str, required=True, help="Path to the experiment run directory (e.g., .../run_2025-...)")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.run_dir):
        print(f"Error: Directory not found: {args.run_dir}")
    else:
        analyze_experiment(args.run_dir)